{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "food_recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8jqbWxcArKm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thedir = '/content/drive/MyDrive/Colab Notebooks/food recognition/images/train'\n",
        "categories = [ name for name in os.listdir(thedir) if os.path.isdir(os.path.join(thedir, name)) ]"
      ],
      "metadata": {
        "id": "n7826K2_Pip6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMBO2J5uPzc7",
        "outputId": "95834e24-d502-4287-d1d9-e43c547bb73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['club_sandwich', 'hot_dog', 'churros', 'cheese_plate', 'donuts', 'sashimi', 'pad_thai', 'cheesecake', 'crab_cakes', 'lobster_bisque', 'caprese_salad', 'gyoza', 'beef_tartare', 'french_fries', 'pork_chop', 'bread_pudding', 'breakfast_burrito', 'onion_rings', 'fish_and_chips', 'ice_cream', 'miso_soup', 'deviled_eggs', 'chocolate_cake', 'pho', 'tuna_tartare', 'foie_gras', 'grilled_cheese_sandwich', 'cup_cakes', 'ceviche', 'chocolate_mousse', 'greek_salad', 'hamburger', 'caesar_salad', 'eggs_benedict', 'pancakes', 'guacamole', 'creme_brulee', 'edamame', 'clam_chowder', 'risotto', 'shrimp_and_grits', 'filet_mignon', 'nachos', 'fried_rice', 'ravioli', 'peking_duck', 'pizza', 'macarons', 'bibimbap', 'mussels', 'french_toast', 'french_onion_soup', 'garlic_bread', 'beet_salad', 'escargots', 'dumplings', 'baklava', 'croque_madame', 'spaghetti_bolognese', 'sushi', 'grilled_salmon', 'omelette', 'tacos', 'baby_back_ribs', 'waffles', 'macaroni_and_cheese', 'hummus', 'poutine', 'gnocchi', 'ramen', 'seaweed_salad', 'frozen_yogurt', 'beignets', 'falafel', 'samosa', 'panna_cotta', 'apple_pie', 'pulled_pork_sandwich', 'lobster_roll_sandwich', 'bruschetta', 'chicken_quesadilla', 'fried_calamari', 'hot_and_sour_soup', 'chicken_curry', 'red_velvet_cake', 'oysters', 'scallops', 'lasagna', 'tiramisu', 'paella', 'cannoli', 'chicken_wings', 'prime_rib', 'beef_carpaccio', 'strawberry_shortcake', 'huevos_rancheros', 'steak', 'spaghetti_carbonara', 'carrot_cake', 'spring_rolls', 'takoyaki']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = [224, 224]\n",
        "\n",
        "train = '/content/drive/MyDrive/Colab Notebooks/food recognition/images/train'\n",
        "test = '/content/drive/MyDrive/Colab Notebooks/food recognition/images/test'"
      ],
      "metadata": {
        "id": "sheZl_AnBJrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG19(input_shape=image_size + [3], weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "Q67jepVVBfPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "-VZV0oA6Bjbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = glob('/content/drive/MyDrive/Colab Notebooks/food recognition/images/train/*')\n",
        "len(folders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNwgCz_JBqA_",
        "outputId": "118fc8df-638d-46ce-9297-8d53172eb709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(vgg.output)\n",
        "prediction = Dense(len(folders), activation='softmax')(x)"
      ],
      "metadata": {
        "id": "HFclI3qdB1Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=vgg.input, outputs=prediction)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76-Y5ytQB94K",
        "outputId": "877c77fc-9868-40d7-8828-798d5f137872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 101)               2533989   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,558,373\n",
            "Trainable params: 2,533,989\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "HTPxfPDFCBPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "pc4xGt1VCUXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory(train, \n",
        "                                                 target_size = [224, 224], \n",
        "                                                 batch_size = 32, \n",
        "                                                 class_mode = 'categorical')\n",
        "test_set = test_datagen.flow_from_directory(test, \n",
        "                                            target_size = [224, 224], \n",
        "                                            batch_size = 32, \n",
        "                                            class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0RkLFqNCYoc",
        "outputId": "1acfe206-5dc5-424e-f0b8-490ffbf8f832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1010 images belonging to 101 classes.\n",
            "Found 416 images belonging to 101 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=20,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-qLIYC5CejB",
        "outputId": "66ad9b04-a9c5-4eb9-c251-dfea8a57692c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 19s 565ms/step - loss: 7.5349 - accuracy: 0.0149 - val_loss: 5.7644 - val_accuracy: 0.0721\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 18s 556ms/step - loss: 3.2884 - accuracy: 0.3356 - val_loss: 5.0290 - val_accuracy: 0.1082\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 18s 567ms/step - loss: 2.0197 - accuracy: 0.5495 - val_loss: 5.3343 - val_accuracy: 0.1514\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 18s 559ms/step - loss: 1.2257 - accuracy: 0.7287 - val_loss: 5.0144 - val_accuracy: 0.1346\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 18s 571ms/step - loss: 0.7623 - accuracy: 0.8208 - val_loss: 5.0021 - val_accuracy: 0.1562\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 18s 563ms/step - loss: 0.5143 - accuracy: 0.8911 - val_loss: 5.0542 - val_accuracy: 0.1538\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 18s 554ms/step - loss: 0.3022 - accuracy: 0.9277 - val_loss: 4.9769 - val_accuracy: 0.1683\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 18s 562ms/step - loss: 0.2763 - accuracy: 0.9327 - val_loss: 5.2752 - val_accuracy: 0.1202\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 18s 557ms/step - loss: 0.2125 - accuracy: 0.9475 - val_loss: 5.1022 - val_accuracy: 0.1514\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 18s 559ms/step - loss: 0.1251 - accuracy: 0.9812 - val_loss: 4.9929 - val_accuracy: 0.1562\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 18s 555ms/step - loss: 0.0842 - accuracy: 0.9911 - val_loss: 4.9759 - val_accuracy: 0.1562\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 18s 556ms/step - loss: 0.0471 - accuracy: 0.9970 - val_loss: 4.8528 - val_accuracy: 0.1538\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 18s 558ms/step - loss: 0.0503 - accuracy: 0.9970 - val_loss: 4.9432 - val_accuracy: 0.1755\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 18s 554ms/step - loss: 0.0436 - accuracy: 0.9941 - val_loss: 4.9940 - val_accuracy: 0.1587\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 18s 552ms/step - loss: 0.0411 - accuracy: 0.9941 - val_loss: 4.8791 - val_accuracy: 0.1659\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 18s 556ms/step - loss: 0.0292 - accuracy: 0.9980 - val_loss: 5.1112 - val_accuracy: 0.1466\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 18s 553ms/step - loss: 0.0239 - accuracy: 0.9990 - val_loss: 4.8185 - val_accuracy: 0.1779\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 18s 552ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 4.9368 - val_accuracy: 0.1514\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 18s 554ms/step - loss: 0.0224 - accuracy: 0.9990 - val_loss: 4.8737 - val_accuracy: 0.1827\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 18s 554ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 4.9055 - val_accuracy: 0.1707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/food recognition/model_food_recognition_vgg19.h5')"
      ],
      "metadata": {
        "id": "afmRkCTkCmsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "5UlMpyuVGKfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m=load_model('/content/drive/MyDrive/Colab Notebooks/food recognition/model_food_recognition_vgg19.h5')"
      ],
      "metadata": {
        "id": "UQy-g3L_JaDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=image.load_img('/content/drive/MyDrive/Colab Notebooks/food recognition/index.jpeg',target_size=(224,224))"
      ],
      "metadata": {
        "id": "mEl7UAyxJih1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = image.img_to_array(img)\n"
      ],
      "metadata": {
        "id": "gHlQmPiFONUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=x/255\n",
        "x=np.expand_dims(x,axis=0)\n",
        "img_data=preprocess_input(x)\n",
        "img_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3coLIx6LOR6T",
        "outputId": "b6e0e12b-15b9-4b09-d91f-9a4fa4be3c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_out = np.argmax(model.predict(img_data), axis=1)\n",
        "y_out = categories[y_out[0]]\n",
        "print(y_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtefqHz8Of6J",
        "outputId": "c071dff1-b7ba-4257-ff0e-17f6ee4d4f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "crab_cakes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MO8amQMWQsJo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}